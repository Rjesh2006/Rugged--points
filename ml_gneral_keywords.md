# Machine Learning and Neural Network Concepts

### Key Concepts:

*1. Greater Normalization:*  
   - *Definition:* Normalization scales input data to ensure consistency and facilitate learning. Greater normalization implies scaling data to a larger extent.
   
*2. Boltzmann Machine in Machine Learning:*  
   - *Definition:* A Boltzmann Machine is a stochastic recurrent neural network modeling the probability distribution of input data.
   
*3. Activation Functions in Neural Networks:*  
   - *Definition:* Activation functions introduce non-linearity to the output of a neural network layer.
   
*4. Cost Function in Machine Learning:*  
   - *Definition:* Cost function measures the disparity between predicted and actual values, aiming to minimize it during training.
   
*5. Gradient Descent:*  
   - *Definition:* Optimization algorithm iteratively adjusts model parameters to minimize the cost function.
   
*6. Backpropagation:*  
   - *Definition:* Method for calculating gradients of the cost function with respect to model parameters.
   
*7. Feedforward:*  
   - *Definition:* Passing input data through a neural network from input to output layers without feedback loops.
   
*8. Hyperparameters:*  
   - *Definition:* Configuration settings governing the learning process of a machine learning model.
   
*9. Dropout and Batch Normalization:*  
   - *Definition:* Regularization techniques to prevent overfitting and improve training stability.
   
*10. Overfitting and Underfitting:*  
   - *Definition:* Model performance issues related to learning too much or too little from the training data.
   
*11. Weight Initialization in Neural Networks:*  
   - *Definition:* Setting initial values for the weights of a neural network to facilitate learning.
   
*12. Conventional Neural Networks:*  
   - *Definition:* Feedforward neural networks consisting of interconnected layers of neurons for various tasks.
